<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>data science on Tejas Siripurapu</title><link>https://teejas.github.io/tags/data-science/</link><description>Recent content in data science on Tejas Siripurapu</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>Â© Athul</copyright><lastBuildDate>Tue, 23 Feb 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://teejas.github.io/tags/data-science/index.xml" rel="self" type="application/rss+xml"/><item><title>Investigating Global COVID-19 Vaccinations</title><link>https://teejas.github.io/notebooks/covid-19-vaccinations/</link><pubDate>Tue, 23 Feb 2021 00:00:00 +0000</pubDate><guid>https://teejas.github.io/notebooks/covid-19-vaccinations/</guid><description>Introduction I&amp;rsquo;m curious to see how vaccination rates compare between countries and within countries (specifically the United States, India, and Israel).
Israel is the country with the fastest vaccination rate, already surpassing 30% of the total population vaccinated. I&amp;rsquo;m curious to see how this compares to the other local Arab states (I know the UAE is in second in terms of vaccination rate), and how vaccination rates among Palestinians compare, if that data is available.</description></item><item><title>Genre Classification and Recommendations Using the FMA Dataset</title><link>https://teejas.github.io/notebooks/fma_rec_and_genre_classification/</link><pubDate>Thu, 23 Jul 2020 00:00:00 +0000</pubDate><guid>https://teejas.github.io/notebooks/fma_rec_and_genre_classification/</guid><description>Introduction Working with the FMA dataset which contains audio features and free music snippets on 100k+ tracks. This is in the interest of working towards my own MIR using deep learning to extract audio features from audio signals (probably using GTZAN). The data comes from the FMA dataset. Let&amp;rsquo;s start by training a model to do feature extraction given an MFCC (derived from an audio signal). We can use the Echonest dataset which comes with audio features already extracted and use the FMA set with librosa to generate the MFCC.</description></item></channel></rss>